{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from cids.util import misc_funcs as misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = misc.data_raw(scvic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading\n",
      "Done loading\n"
     ]
    }
   ],
   "source": [
    "for path in [\"CidsSampleNormal_Tensor_28\",\"CidsSampleAttack_Tensor_28\"]:\n",
    "    with open(os.path.join(data_dir, f\"{path}.pkl\"), 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    print(\"Done loading\")\n",
    "    data = torch.utils.data.default_collate(data)\n",
    "    with h5py.File(os.path.join(data_dir, f'{path}.h5'), 'w') as f:\n",
    "        f.create_dataset('network', data=data[0].numpy())\n",
    "        f.create_dataset('host', data=data[1].numpy())\n",
    "        f.create_dataset('logs', data=np.array(data[2], dtype=h5py.string_dtype(encoding='utf-8')))\n",
    "        f.create_dataset('label', data=np.array(data[3], dtype=h5py.string_dtype(encoding='utf-8')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_dir, \"Msg2Vec_Bert_100.pkl\"), 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "print(\"Done loading\")\n",
    "\n",
    "with h5py.File(os.path.join(data_dir,  \"Msg2Vec_Bert_100.h5\"), 'w') as f:\n",
    "    f.create_dataset('logs', data=np.array(data[0], dtype=h5py.string_dtype(encoding='utf-8')))\n",
    "    f.create_dataset('embeddings', data=data[1].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "460547\n",
      "460547\n",
      "460547\n",
      "460547\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(data))\n",
    "for i in range(4):\n",
    "    print(len(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(data_dir, 'CidsSampleNormal_Tensor_28.h5'), 'r') as f:\n",
    "    network = f['network'][:]\n",
    "    host = f['host'][:]\n",
    "    \n",
    "    # Load the variable-length strings\n",
    "    logs =  f['logs'][:]\n",
    "    labels = f['label'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = [s.decode('utf-8') for s in logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = [s.decode('utf-8') for s in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data_structure = []\n",
    "for i in range(len(network)):\n",
    "        tensor1 = torch.tensor(network[i])\n",
    "        tensor2 = torch.tensor(host[i])\n",
    "        loaded_data_structure.append((tensor1, tensor2, logs[i], labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "460547\n",
      "<class 'tuple'>\n",
      "4\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([132])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([28, 8])\n",
      "<class 'str'>\n",
      "The Amazon SSM Agent service terminated unexpectedly.  It has done this 208 time(s).  The following corrective action will be taken in 30000 milliseconds: Restart the service. The Amazon SSM Agent service terminated with the following service-specific error: \n",
      "Incorrect function. The Amazon SSM Agent service entered the stopped state.\n",
      "<class 'str'>\n",
      "Benign\n"
     ]
    }
   ],
   "source": [
    "data = loaded_data_structure\n",
    "print(type(data))\n",
    "print(len(data))\n",
    "print(type(data[0]))\n",
    "print(len(data[0]))\n",
    "for i in range(len(data[0])):\n",
    "    print(type(data[0][i]))\n",
    "    if isinstance(data[0][i], torch.Tensor):\n",
    "        print(data[0][i].shape)\n",
    "    if isinstance(data[0][i], str):\n",
    "        print(data[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "460547\n",
      "['The Amazon SSM Agent service terminated unexpectedly.  It has done this 208 time(s).  The following corrective action will be taken in 30000 milliseconds: Restart the service. The Amazon SSM Agent service terminated with the following service-specific error: \\r\\nIncorrect function. The Amazon SSM Agent service entered the stopped state.']\n",
      "<class 'str'>\n",
      "<class 'numpy.ndarray'>\n",
      "460547\n",
      "[b'Benign']\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "print(type(logs))\n",
    "print(len(logs))\n",
    "print(logs[:1])\n",
    "print(type(logs[0]))\n",
    "print(type(labels))\n",
    "print(len(labels))\n",
    "print(labels[:1])\n",
    "print(type(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([460547, 132]) torch.Size([460547, 28, 8])\n"
     ]
    }
   ],
   "source": [
    "print(network.shape, host.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists(os.path.join(misc.data_raw(True), \"CidsSampleNormal_Tensor_28.h5\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cids3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
